{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/SharedFolder/git/tillvolkmann/night-drive')\n",
    "sys.path.append('/home/SharedFolder/git/tillvolkmann/night-drive/classifier')\n",
    "sys.path.append('/home/SharedFolder/git/tillvolkmann/night-drive/utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "import subprocess\n",
    "import numpy as np\n",
    "#from eval_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify device\n",
    "device = \"cuda\"\n",
    "\n",
    "# specify paths\n",
    "path_to_videos = \"/home/SharedFolder/CurrentDatasets/bdd100k_video_samples\"\n",
    "weights_classification = \"/home/SharedFolder/trained_models/night-drive/timeofday_classifier/resnet18_timeofday_daynight_classifier_best.pth\"\n",
    "\n",
    "# confidence thresholds, set between 0 and 1 to enable module\n",
    "conf_thresh_classification = 0.7\n",
    "\n",
    "# mapping dict for timeofday predictions\n",
    "dict_timeofday = {\n",
    "     0: \"Night\",\n",
    "     1: \"Day\"\n",
    "}\n",
    "\n",
    "# for separating temporary folders when using multiple workers\n",
    "worker_name = \"worker_CAM2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile_suffix = \"_timeofday\"\n",
    "print(outfile_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = glob.glob(path_to_videos + \"/*.mov\")\n",
    "random.seed(123)\n",
    "random.shuffle(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CAM_resnet18_BC(image_path, weights_path, class_dict, n_outputs, device):\n",
    "    \"\"\"\n",
    "    CAM code from https://github.com/metalbubble/CAM/blob/master/pytorch_CAM.py\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from PIL import Image\n",
    "    from torch.nn import functional as F\n",
    "    from torchvision import models, transforms\n",
    "    from torch.autograd import Variable\n",
    "\n",
    "    net = models.resnet18(pretrained=True)\n",
    "    finalconv_name = 'layer4'\n",
    "    net.fc = nn.Linear(net.fc.in_features, n_outputs)\n",
    "    net.load_state_dict(torch.load(weights_path)[\"model_state_dict\"])\n",
    "    net.eval()\n",
    "\n",
    "    # hook the feature extractor\n",
    "    features_blobs = []\n",
    "\n",
    "    def hook_feature(module, input, output):\n",
    "        features_blobs.append(output.data.cpu().numpy())\n",
    "\n",
    "    net._modules.get(finalconv_name).register_forward_hook(hook_feature)\n",
    "\n",
    "    # get the softmax weight\n",
    "    params = list(net.parameters())\n",
    "    weight_softmax = np.squeeze(params[-2].data.numpy())\n",
    "\n",
    "    def returnCAM(feature_conv, weight_softmax):\n",
    "        # generate the class activation maps upsample to 256x256\n",
    "        size_upsample = (256, 256)\n",
    "        bz, nc, h, w = feature_conv.shape\n",
    "        output_cam = []\n",
    "        cam = weight_softmax.dot(feature_conv.reshape((nc, h * w)))\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "        return output_cam\n",
    "\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    preprocess = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), normalize])\n",
    "\n",
    "    img_pil = Image.open(image_path)\n",
    "    img_tensor = preprocess(img_pil)\n",
    "    img_variable = Variable(img_tensor.unsqueeze(0))\n",
    "\n",
    "    net.to(torch.device(device))\n",
    "       \n",
    "    img_variable = img_variable.to(torch.device(device))\n",
    "    logit = net(img_variable)\n",
    "    logit = logit.cpu()\n",
    "    \n",
    "    #h_x = F.softmax(logit, dim=1).data.squeeze()\n",
    "    #probs, idx = h_x.sort(0, True)\n",
    "    \n",
    "    h_x = F.sigmoid(logit).data.squeeze()\n",
    "    probs, idx = h_x.sort(0, True)\n",
    "    probs = probs.numpy()\n",
    "    idx = idx.numpy()\n",
    "    if (probs) >= 0.5:\n",
    "        idx = 1\n",
    "    else:\n",
    "        idx = 0\n",
    "    probs = np.append(probs, 1 - probs)\n",
    "    idx = np.append(idx, 1 - idx)\n",
    "    sort_idx = np.argsort(probs)\n",
    "    probs = probs[sort_idx]\n",
    "    idx = idx[sort_idx]\n",
    "    probs = probs[::-1]\n",
    "    idx = idx[::-1]   \n",
    "\n",
    "    # generate class activation mapping for the top1 prediction\n",
    "    CAMs = returnCAM(features_blobs[0], weight_softmax)\n",
    "\n",
    "    # render the CAM and output\n",
    "    img = cv2.imread(image_path)\n",
    "    height, width, _ = img.shape\n",
    "    heatmap = cv2.applyColorMap(cv2.resize(CAMs[0], (width, height)), cv2.COLORMAP_JET)\n",
    "    result_bgr = heatmap * 0.3 + img * 0.5\n",
    "\n",
    "    return class_dict[idx[0]], probs[0], result_bgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video, dict_timeofday, conf_thresh_classification, device):\n",
    "    # (re-) create directories for extracted frames and target video\n",
    "    file_name = os.path.basename(video)\n",
    "    path_name = os.path.dirname(video)\n",
    "    temp_path = os.path.join(path_name, worker_name, file_name.split(\".\")[0])\n",
    "    temp_pred_path = os.path.join(temp_path, \"prediction\")\n",
    "    target_path = os.path.join(path_name, \"demovideos_CAM\")\n",
    "    target_file = os.path.join(target_path,file_name.split(\".mov\")[0] + outfile_suffix + \".mp4\")\n",
    "    if not os.path.isdir(target_path):\n",
    "        os.makedirs(target_path, exist_ok = True)\n",
    "    elif os.path.exists(target_file):\n",
    "        # do nothing if file already processed\n",
    "        return 0    \n",
    "    if os.path.isdir(temp_path):\n",
    "        shutil.rmtree(temp_path)\n",
    "    os.makedirs(temp_path, exist_ok = True)\n",
    "    os.makedirs(temp_pred_path, exist_ok = True)\n",
    "    # extract frames from video\n",
    "    bash_cmd = [\"ffmpeg\", \"-i\", video, \"-start_number\", \"0\", \"-qscale:v\", \"2\", temp_path + \"/frame-%d.jpg\"]\n",
    "    subprocess.call(bash_cmd)\n",
    "    # process frames\n",
    "    frames = glob.glob(temp_path + \"/*.jpg\")\n",
    "    for frame in frames:\n",
    "        # classify weather and get CAM\n",
    "        pred_weather_class, pred_weather_score, cam_bgr = get_CAM_resnet18_BC(frame, weights_classification, dict_timeofday, 1, device)\n",
    "        # write weather on image\n",
    "        weather_color = [(255, 255, 255) if pred_weather_score >= conf_thresh_classification else (80, 80, 80)]\n",
    "        cv2.putText(cam_bgr,\n",
    "                    f\"{pred_weather_class} ({pred_weather_score:.2f})\", \n",
    "                    (5, 715), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.8, \n",
    "                    weather_color[0], \n",
    "                    2)\n",
    "        # write bgr (will be transformed to rgb by open cv)\n",
    "        cv2.imwrite(os.path.join(temp_pred_path, os.path.basename(frame)), \n",
    "                    cam_bgr, \n",
    "                    [int(cv2.IMWRITE_JPEG_QUALITY), 95])\n",
    "    # construct video\n",
    "    bash_cmd = [\"ffmpeg\", \"-r\", \"30\", \"-f\", \"image2\", \"-i\", temp_pred_path + \"/frame-%d.jpg\", \"-vcodec\", \"libx264\", \"-crf\", \"18\", target_file]\n",
    "    subprocess.call(bash_cmd)\n",
    "    # clean-up\n",
    "    shutil.rmtree(temp_path)\n",
    "    return len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(videos)):\n",
    "    print(f\"Processing video {i + 1} of {len(videos)}\", end = \"\")\n",
    "    tic = time.time()\n",
    "    n_frames = process_video(videos[i], dict_timeofday, conf_thresh_classification, device)\n",
    "    toc = time.time()\n",
    "    if n_frames > 0:\n",
    "        print(f\"... done in {toc - tic:.2f}s ({((toc - tic) / n_frames):.2f}s / frame)\")\n",
    "    else:\n",
    "        print(f\"... skipped. File exists.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
