{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copyfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import BDDDataSets as bdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = '/home/till/projects/night-drive/config/config_bdd_make_datasets.json'\n",
    "cfg = bdd.GetConfig(cfg_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Loading BDD training label dataset\n",
      ">> Loading BDD validation label dataset\n"
     ]
    }
   ],
   "source": [
    "# Load full BDD dataset\n",
    "data = bdd.BaseDataset(cfg)\n",
    "data = data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>name</th>\n",
       "      <th>weather</th>\n",
       "      <th>timeofday</th>\n",
       "      <th>scene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'category': 'traffic light', 'attributes': {...</td>\n",
       "      <td>/home/till/data/driving/BerkeleyDeepDrive/bdd1...</td>\n",
       "      <td>clear</td>\n",
       "      <td>daytime</td>\n",
       "      <td>city street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'category': 'traffic sign', 'attributes': {'...</td>\n",
       "      <td>/home/till/data/driving/BerkeleyDeepDrive/bdd1...</td>\n",
       "      <td>clear</td>\n",
       "      <td>night</td>\n",
       "      <td>city street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'category': 'car', 'attributes': {'occluded'...</td>\n",
       "      <td>/home/till/data/driving/BerkeleyDeepDrive/bdd1...</td>\n",
       "      <td>clear</td>\n",
       "      <td>night</td>\n",
       "      <td>highway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'category': 'car', 'attributes': {'occluded'...</td>\n",
       "      <td>/home/till/data/driving/BerkeleyDeepDrive/bdd1...</td>\n",
       "      <td>clear</td>\n",
       "      <td>night</td>\n",
       "      <td>city street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'category': 'car', 'attributes': {'occluded'...</td>\n",
       "      <td>/home/till/data/driving/BerkeleyDeepDrive/bdd1...</td>\n",
       "      <td>rainy</td>\n",
       "      <td>night</td>\n",
       "      <td>highway</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              labels  \\\n",
       "0  [{'category': 'traffic light', 'attributes': {...   \n",
       "1  [{'category': 'traffic sign', 'attributes': {'...   \n",
       "2  [{'category': 'car', 'attributes': {'occluded'...   \n",
       "3  [{'category': 'car', 'attributes': {'occluded'...   \n",
       "4  [{'category': 'car', 'attributes': {'occluded'...   \n",
       "\n",
       "                                                name weather timeofday  \\\n",
       "0  /home/till/data/driving/BerkeleyDeepDrive/bdd1...   clear   daytime   \n",
       "1  /home/till/data/driving/BerkeleyDeepDrive/bdd1...   clear     night   \n",
       "2  /home/till/data/driving/BerkeleyDeepDrive/bdd1...   clear     night   \n",
       "3  /home/till/data/driving/BerkeleyDeepDrive/bdd1...   clear     night   \n",
       "4  /home/till/data/driving/BerkeleyDeepDrive/bdd1...   rainy     night   \n",
       "\n",
       "         scene  \n",
       "0  city street  \n",
       "1  city street  \n",
       "2      highway  \n",
       "3  city street  \n",
       "4      highway  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>weather</th>\n",
       "      <th>clear</th>\n",
       "      <th>cloudy</th>\n",
       "      <th>rainy</th>\n",
       "      <th>snowy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timeofday</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>daytime</th>\n",
       "      <td>14218</td>\n",
       "      <td>13490</td>\n",
       "      <td>2918</td>\n",
       "      <td>3284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night</th>\n",
       "      <td>26158</td>\n",
       "      <td>144</td>\n",
       "      <td>2494</td>\n",
       "      <td>2522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "weather    clear  cloudy  rainy  snowy\n",
       "timeofday                             \n",
       "daytime    14218   13490   2918   3284\n",
       "night      26158     144   2494   2522"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-tabulation of available samples in space time x weather\n",
    "crosstab_total = pd.crosstab(data['timeofday'], data['weather'])\n",
    "crosstab_total = crosstab_total.reindex(sorted(crosstab_total.columns), axis=1)  # columns need to be in same order as sampler_table\n",
    "crosstab_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "class InsufficientSamplesWarning(UserWarning):\n",
    "    pass    \n",
    "\n",
    "def stratified_sampler(cross_total, cross_avail, sampler_dict, verbose=1):\n",
    "    \n",
    "    # initialize empty sampler table\n",
    "    sampler_tab = cross_total.copy()\n",
    "    sampler_tab[:] = 0\n",
    "    \n",
    "    # get some helpers\n",
    "    _weather_classes = sampler_tab.columns\n",
    "    _num_weather_classes = len(_weather_classes)\n",
    "    _timeofday_classes = sampler_tab.index\n",
    "    \n",
    "    # First, we need to apply the class_min threshold\n",
    "    if sampler_dict[\"class_min\"] is not None:\n",
    "        for tod in _timeofday_classes:\n",
    "            if sampler_dict[\"class_dist\"][tod] > 0:\n",
    "               sampler_tab.loc[tod] = cross_avail.loc[tod].apply(lambda x: np.minimum(x,sampler_dict[\"class_min\"]))  # minimum of requested and available samples\n",
    "               sampler_tab.loc[tod] = np.minimum(sampler_tab.loc[tod], cross_avail.loc[tod])\n",
    "    # Second, we sample the remaining images according to the specified distribution across weather classes\n",
    "    if sampler_dict[\"balancing\"] == \"none\":\n",
    "        # day and night eq to their respective dist\n",
    "        _dist_weather_classes = cross_total.div(cross_total.sum(axis=1), axis=0)\n",
    "    \n",
    "    elif sampler_dict[\"balancing\"] == \"like-day-and-night\":\n",
    "        # day and night eq to their combined dist (note this is not weightes by number of samples among timeofday categories, i.e. the weather dists during day and night have equal weight)\n",
    "        _dist_weather_classes = cross_total.copy()\n",
    "        _dist_weather_classes.loc[\"daytime\"] =  cross_total.div(cross_total.sum(axis=1), axis=0).mean(axis=0)\n",
    "        _dist_weather_classes.loc[\"night\"] =  _dist_weather_classes.loc[\"daytime\"]\n",
    "\n",
    "    elif sampler_dict[\"balancing\"] == \"like-day\":\n",
    "        # day and night eq to day's dist\n",
    "        _dist_weather_classes = cross_total.copy()\n",
    "        _dist_weather_classes.loc[\"daytime\"] =  cross_total.loc[\"daytime\"].div(cross_total.loc[\"daytime\"].sum(), axis=0)\n",
    "        _dist_weather_classes.loc[\"night\"] =  _dist_weather_classes.loc[\"daytime\"]\n",
    "        \n",
    "    elif sampler_dict[\"balancing\"] in [\"max-each\",\"max-adjusted\",\"max-adjusted-unequal\"]:\n",
    "        # maximum balance within each time of day subgroup\n",
    "        _dist_weather_classes = cross_total.copy()\n",
    "        _dist_weather_classes[:] = 1/_num_weather_classes\n",
    "        \n",
    "    print(_dist_weather_classes)\n",
    "    # Third, convert distributions to requested numbers of images\n",
    "    #     \"over\": \"before\" ~ assumes oversampling before counting\n",
    "    #     \"over\": \"after\" ~ assumes oversampling after counting\n",
    "    if sampler_dict[\"over\"] == \"before\":\n",
    "        # assumes oversampling is done before sample collection; i.e., split set will have specified fraction of \"resampled\" images of each timeofday\n",
    "        for tod in _timeofday_classes:\n",
    "            # get target number of samples per weather class (after oversampling)\n",
    "            _class_size = sampler_dict[\"n\"] * sampler_dict[\"class_dist\"][tod] / _num_weather_classes\n",
    "            # get num of original images to draw to match class target size and specified distibution\n",
    "            _num_originals = _class_size * _dist_weather_classes.loc[tod] / _dist_weather_classes.loc[tod].max()  # note the scaling of the weather dist to a [0 1] range, so that the max class exactly fills the target while preserving the desired distribution\n",
    "            # assign to sampler table (accounting for already assigned data from thresholding)\n",
    "            sampler_tab.loc[tod] = np.maximum(sampler_tab.loc[tod], _num_originals)\n",
    "            \n",
    "    elif sampler_dict[\"over\"] in [\"none\", \"after\"]:\n",
    "        # assumes oversampling is done after sample collection; i.e., split set will have specified fraction of \"unqiue\" images of each timeofday\n",
    "         for tod in _timeofday_classes:\n",
    "            print(_dist_weather_classes.loc[tod])\n",
    "            _num_originals = sampler_dict[\"n\"] * sampler_dict[\"class_dist\"][tod] * _dist_weather_classes.loc[tod]\n",
    "            # correct for class_min threshold\n",
    "            _temp_diff = _num_originals - sampler_tab.loc[tod]\n",
    "            _bias = _temp_diff.where(_temp_diff < 0).fillna(0).sum()\n",
    "            _capped_bool = _temp_diff < 0\n",
    "            _temp_dist = _dist_weather_classes.loc[tod]\n",
    "            _temp_dist[_capped_bool] = 0\n",
    "            _temp_dist = _temp_dist/_temp_dist.sum()\n",
    "            _num_originals = _num_originals + _temp_dist * _bias\n",
    "            # here, we could correct for availability if wanted, though this would alter the requested distribution\n",
    "            # _do_correct = True\n",
    "            # if _do_correct:\n",
    "            # now assign\n",
    "            sampler_tab.loc[tod] = np.maximum(sampler_tab.loc[tod], _num_originals)\n",
    "\n",
    "    \n",
    "    # max balancing but adjust so that proportions among sets of different sizes (e.g. 25% night and 50%) are preserved\n",
    "    # \"max-adjusted\" preserves with respect to 100% sample size, while \"max-adjusted-unequal\" preserves with respect to the max percentage sample size in the experiment (i.e. 50% night)\n",
    "    if sampler_dict[\"balancing\"] in [\"max-adjusted\"]:\n",
    "            sampler_tab.loc[\"daytime\"] = np.minimum( sampler_tab.loc[\"daytime\"], cross_avail.loc[\"daytime\"] * sampler_dict[\"class_dist\"][\"daytime\"])\n",
    "            sampler_tab.loc[\"night\"] = np.minimum( sampler_tab.loc[\"night\"], cross_avail.loc[\"night\"] * sampler_dict[\"class_dist\"][\"night\"])\n",
    "    if sampler_dict[\"balancing\"] in [\"max-adjusted-unequal\"]:\n",
    "            sampler_tab.loc[\"daytime\"] = np.minimum( sampler_tab.loc[\"daytime\"], cross_avail.loc[\"daytime\"] * sampler_dict[\"class_dist\"][\"daytime\"])\n",
    "            sampler_tab.loc[\"night\"] = np.minimum( sampler_tab.loc[\"night\"], cross_avail.loc[\"night\"] * sampler_dict[\"class_dist\"][\"night\"] * 1/0.5)\n",
    "   \n",
    "    # correct for actually available numbers\n",
    "    if (sampler_tab > cross_avail).any().any():\n",
    "        # issue a warning\n",
    "        warnings.warn('Number of available sample images is smaller than number of requested images.', InsufficientSamplesWarning)\n",
    "        print(\"\\n====================================================\")\n",
    "        print(\"States during InsufficientSamplesWarning from stratified_sampler\")\n",
    "        print(\"====================================================\")\n",
    "        print(\"\\nsampler_tab during Warning\")\n",
    "        print(sampler_tab)\n",
    "        print(\"\\ncross_avail during Warning\")\n",
    "        print(cross_avail)\n",
    "        print(\"\\nsampler_tab > cross_avail during Warning\")\n",
    "        print(sampler_tab > cross_avail)\n",
    "        # make correction\n",
    "        sampler_tab[sampler_tab > cross_avail] = cross_avail[sampler_tab > cross_avail]        \n",
    "    \n",
    "    # Fourth, determine n to over-sample\n",
    "    over_tab = sampler_tab.copy()\n",
    "    over_tab[:] = 0\n",
    "    if sampler_dict[\"over\"] != \"none\":\n",
    "        over_tab.loc[\"daytime\"] = sampler_tab.loc[\"daytime\"].max() - sampler_tab.loc[\"daytime\"]\n",
    "        over_tab.loc[\"night\"]   = sampler_tab.loc[\"night\"].max() - sampler_tab.loc[\"night\"]\n",
    "\n",
    "    # finally, convert to int\n",
    "    sampler_tab = sampler_tab.round()\n",
    "    sampler_tab = sampler_tab.astype(\"int32\", copy=True)\n",
    "    over_tab = over_tab.round()\n",
    "    over_tab = over_tab.astype(\"int32\", copy=True)\n",
    "    \n",
    "    # print some stats\n",
    "   \n",
    "    if verbose > 0:\n",
    "        # Output basic summary information\n",
    "        \n",
    "        print(\"\\n====================================================\")\n",
    "        print(\"Summary statistics from stratified_sampler\")\n",
    "        print(\"====================================================\")\n",
    "        \n",
    "        print(\"\\nsampler_tab\")\n",
    "        sampler_tab_show = sampler_tab.copy()\n",
    "        sampler_tab_show.loc[:,'total'] = sampler_tab_show.sum(axis=1)\n",
    "        sampler_tab_show.loc['total',:] = sampler_tab_show.sum(axis=0)\n",
    "        sampler_tab_show = sampler_tab_show.astype(\"int32\")\n",
    "        print(sampler_tab_show)\n",
    "\n",
    "        print(\"\\nover_tab\")\n",
    "        over_tab_show = over_tab.copy()\n",
    "        over_tab_show.loc[:,'total'] = over_tab_show.sum(axis=1)\n",
    "        over_tab_show.loc['total',:] = over_tab_show.sum(axis=0)\n",
    "        over_tab_show = over_tab_show.astype(\"int32\")\n",
    "        print(over_tab_show)\n",
    "\n",
    "        print(\"\\nsampler_tab + over_tab\")\n",
    "        comb_tab_show = over_tab_show + sampler_tab_show\n",
    "        print(comb_tab_show)\n",
    "\n",
    "        print(\"\\nfraction oversampled (%)\")\n",
    "        percover_tab_show = over_tab_show / (over_tab_show + sampler_tab_show) * 100\n",
    "        print(percover_tab_show)\n",
    "        \n",
    "    if verbose > 1:\n",
    "        # Output some extra information\n",
    "        print(\"\\ncross_total\")\n",
    "        print(cross_total)\n",
    "        \n",
    "        print(\"\\ncross_avail\")\n",
    "        print(cross_avail)\n",
    "        \n",
    "        print(\"\\n_dist_weather_classes\")\n",
    "        print(_dist_weather_classes)\n",
    "    \n",
    "    # return sampler table and oversampler table\n",
    "    return sampler_tab, over_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather       clear    cloudy     rainy     snowy\n",
      "timeofday                                        \n",
      "daytime    0.419286  0.397818  0.086051  0.096845\n",
      "night      0.835239  0.004598  0.079635  0.080529\n",
      "weather\n",
      "clear     0.419286\n",
      "cloudy    0.397818\n",
      "rainy     0.086051\n",
      "snowy     0.096845\n",
      "Name: daytime, dtype: float64\n",
      "weather\n",
      "clear     0.835239\n",
      "cloudy    0.004598\n",
      "rainy     0.079635\n",
      "snowy     0.080529\n",
      "Name: night, dtype: float64\n",
      "\n",
      "====================================================\n",
      "Summary statistics from stratified_sampler\n",
      "====================================================\n",
      "\n",
      "sampler_tab\n",
      "weather    clear  cloudy  rainy  snowy  total\n",
      "timeofday                                    \n",
      "daytime      419     398     86     97   1000\n",
      "night        797      50     76     77   1000\n",
      "total       1216     448    162    174   2000\n",
      "\n",
      "over_tab\n",
      "weather    clear  cloudy  rainy  snowy  total\n",
      "timeofday                                    \n",
      "daytime        0       0      0      0      0\n",
      "night          0       0      0      0      0\n",
      "total          0       0      0      0      0\n",
      "\n",
      "sampler_tab + over_tab\n",
      "weather    clear  cloudy  rainy  snowy  total\n",
      "timeofday                                    \n",
      "daytime      419     398     86     97   1000\n",
      "night        797      50     76     77   1000\n",
      "total       1216     448    162    174   2000\n",
      "\n",
      "fraction oversampled (%)\n",
      "weather    clear  cloudy  rainy  snowy  total\n",
      "timeofday                                    \n",
      "daytime      0.0     0.0    0.0    0.0    0.0\n",
      "night        0.0     0.0    0.0    0.0    0.0\n",
      "total        0.0     0.0    0.0    0.0    0.0\n"
     ]
    }
   ],
   "source": [
    "cfg = bdd.GetConfig(cfg_name)\n",
    "# initialize sampler_table and over_table dict to collect all the outputs\n",
    "sampler_table = {}\n",
    "over_table = {}\n",
    "# initialize cross tabulation of remaining available images to choose from\n",
    "crosstab_avail = crosstab_total.copy()\n",
    "\n",
    "# first, we get the test set\n",
    "sampler_table[\"test\"], over_table[\"test\"] = stratified_sampler(crosstab_total, crosstab_avail, cfg.sampler_dict[\"test\"])\n",
    "# update the numbers of remaining available images\n",
    "crosstab_avail = crosstab_avail - sampler_table[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather       clear    cloudy     rainy     snowy\n",
      "timeofday                                        \n",
      "daytime    0.419286  0.397818  0.086051  0.096845\n",
      "night      0.835239  0.004598  0.079635  0.080529\n",
      "weather\n",
      "clear     0.419286\n",
      "cloudy    0.397818\n",
      "rainy     0.086051\n",
      "snowy     0.096845\n",
      "Name: daytime, dtype: float64\n",
      "weather\n",
      "clear     0.835239\n",
      "cloudy    0.004598\n",
      "rainy     0.079635\n",
      "snowy     0.080529\n",
      "Name: night, dtype: float64\n",
      "\n",
      "====================================================\n",
      "Summary statistics from stratified_sampler\n",
      "====================================================\n",
      "\n",
      "sampler_tab\n",
      "weather    clear  cloudy  rainy  snowy  total\n",
      "timeofday                                    \n",
      "daytime      419     398     86     97   1000\n",
      "night        797      50     76     77   1000\n",
      "total       1216     448    162    174   2000\n",
      "\n",
      "over_tab\n",
      "weather    clear  cloudy  rainy  snowy  total\n",
      "timeofday                                    \n",
      "daytime        0       0      0      0      0\n",
      "night          0       0      0      0      0\n",
      "total          0       0      0      0      0\n",
      "\n",
      "sampler_tab + over_tab\n",
      "weather    clear  cloudy  rainy  snowy  total\n",
      "timeofday                                    \n",
      "daytime      419     398     86     97   1000\n",
      "night        797      50     76     77   1000\n",
      "total       1216     448    162    174   2000\n",
      "\n",
      "fraction oversampled (%)\n",
      "weather    clear  cloudy  rainy  snowy  total\n",
      "timeofday                                    \n",
      "daytime      0.0     0.0    0.0    0.0    0.0\n",
      "night        0.0     0.0    0.0    0.0    0.0\n",
      "total        0.0     0.0    0.0    0.0    0.0\n"
     ]
    }
   ],
   "source": [
    "# second, we get the valid set\n",
    "sampler_table[\"valid\"], over_table[\"valid\"] = stratified_sampler(crosstab_total, crosstab_avail, cfg.sampler_dict[\"valid\"])\n",
    "# update the numbers of remaining available images\n",
    "crosstab_avail = crosstab_avail - sampler_table[\"valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather       clear    cloudy     rainy     snowy\n",
      "timeofday                                        \n",
      "daytime    0.419286  0.397818  0.086051  0.096845\n",
      "night      0.419286  0.397818  0.086051  0.096845\n",
      "\n",
      "====================================================\n",
      "Summary statistics from stratified_sampler\n",
      "====================================================\n",
      "\n",
      "sampler_tab\n",
      "weather    clear  cloudy  rainy  snowy  total\n",
      "timeofday                                    \n",
      "daytime    10500    9962   2155   2425  25042\n",
      "night          0       0      0      0      0\n",
      "total      10500    9962   2155   2425  25042\n",
      "\n",
      "over_tab\n",
      "weather    clear  cloudy  rainy  snowy  total\n",
      "timeofday                                    \n",
      "daytime        0     538   8345   8075  16958\n",
      "night          0       0      0      0      0\n",
      "total          0     538   8345   8075  16958\n",
      "\n",
      "sampler_tab + over_tab\n",
      "weather    clear  cloudy  rainy  snowy  total\n",
      "timeofday                                    \n",
      "daytime    10500   10500  10500  10500  42000\n",
      "night          0       0      0      0      0\n",
      "total      10500   10500  10500  10500  42000\n",
      "\n",
      "fraction oversampled (%)\n",
      "weather    clear   cloudy     rainy      snowy     total\n",
      "timeofday                                               \n",
      "daytime      0.0  5.12381  79.47619  76.904762  40.37619\n",
      "night        NaN      NaN       NaN        NaN       NaN\n",
      "total        0.0  5.12381  79.47619  76.904762  40.37619\n",
      "weather       clear    cloudy     rainy     snowy\n",
      "timeofday                                        \n",
      "daytime    0.419286  0.397818  0.086051  0.096845\n",
      "night      0.419286  0.397818  0.086051  0.096845\n",
      "\n",
      "====================================================\n",
      "States during InsufficientSamplesWarning from stratified_sampler\n",
      "====================================================\n",
      "\n",
      "sampler_tab during Warning\n",
      "weather     clear       cloudy        rainy        snowy\n",
      "timeofday                                               \n",
      "daytime    7875.0  7471.778731  1616.208327  1818.926713\n",
      "night      2625.0  2490.592910   538.736109   606.308904\n",
      "\n",
      "cross_avail during Warning\n",
      "weather    clear  cloudy  rainy  snowy\n",
      "timeofday                             \n",
      "daytime    13380   12694   2746   3090\n",
      "night      24564      44   2342   2368\n",
      "\n",
      "sampler_tab > cross_avail during Warning\n",
      "weather    clear  cloudy  rainy  snowy\n",
      "timeofday                             \n",
      "daytime    False   False  False  False\n",
      "night      False    True  False  False\n",
      "\n",
      "====================================================\n",
      "Summary statistics from stratified_sampler\n",
      "====================================================\n",
      "\n",
      "sampler_tab\n",
      "weather    clear  cloudy  rainy  snowy  total\n",
      "timeofday                                    \n",
      "daytime     7875    7472   1616   1819  18782\n",
      "night       2625      44    539    606   3814\n",
      "total      10500    7516   2155   2425  22596\n",
      "\n",
      "over_tab\n",
      "weather    clear  cloudy  rainy  snowy  total\n",
      "timeofday                                    \n",
      "daytime        0     403   6259   6056  12718\n",
      "night          0    2581   2086   2019   6686\n",
      "total          0    2984   8345   8075  19404\n",
      "\n",
      "sampler_tab + over_tab\n",
      "weather    clear  cloudy  rainy  snowy  total\n",
      "timeofday                                    \n",
      "daytime     7875    7875   7875   7875  31500\n",
      "night       2625    2625   2625   2625  10500\n",
      "total      10500   10500  10500  10500  42000\n",
      "\n",
      "fraction oversampled (%)\n",
      "weather    clear     cloudy      rainy      snowy      total\n",
      "timeofday                                                   \n",
      "daytime      0.0   5.117460  79.479365  76.901587  40.374603\n",
      "night        0.0  98.323810  79.466667  76.914286  63.676190\n",
      "total        0.0  28.419048  79.476190  76.904762  46.200000\n",
      "weather       clear    cloudy     rainy     snowy\n",
      "timeofday                                        \n",
      "daytime    0.419286  0.397818  0.086051  0.096845\n",
      "night      0.419286  0.397818  0.086051  0.096845\n",
      "\n",
      "====================================================\n",
      "States during InsufficientSamplesWarning from stratified_sampler\n",
      "====================================================\n",
      "\n",
      "sampler_tab during Warning\n",
      "weather     clear       cloudy        rainy        snowy\n",
      "timeofday                                               \n",
      "daytime    5250.0  4981.185821  1077.472218  1212.617808\n",
      "night      5250.0  4981.185821  1077.472218  1212.617808\n",
      "\n",
      "cross_avail during Warning\n",
      "weather    clear  cloudy  rainy  snowy\n",
      "timeofday                             \n",
      "daytime    13380   12694   2746   3090\n",
      "night      24564      44   2342   2368\n",
      "\n",
      "sampler_tab > cross_avail during Warning\n",
      "weather    clear  cloudy  rainy  snowy\n",
      "timeofday                             \n",
      "daytime    False   False  False  False\n",
      "night      False    True  False  False\n",
      "\n",
      "====================================================\n",
      "Summary statistics from stratified_sampler\n",
      "====================================================\n",
      "\n",
      "sampler_tab\n",
      "weather    clear  cloudy  rainy  snowy  total\n",
      "timeofday                                    \n",
      "daytime     5250    4981   1077   1213  12521\n",
      "night       5250      44   1077   1213   7584\n",
      "total      10500    5025   2154   2426  20105\n",
      "\n",
      "over_tab\n",
      "weather    clear  cloudy  rainy  snowy  total\n",
      "timeofday                                    \n",
      "daytime        0     269   4173   4037   8479\n",
      "night          0    5206   4173   4037  13416\n",
      "total          0    5475   8346   8074  21895\n",
      "\n",
      "sampler_tab + over_tab\n",
      "weather    clear  cloudy  rainy  snowy  total\n",
      "timeofday                                    \n",
      "daytime     5250    5250   5250   5250  21000\n",
      "night       5250    5250   5250   5250  21000\n",
      "total      10500   10500  10500  10500  42000\n",
      "\n",
      "fraction oversampled (%)\n",
      "weather    clear     cloudy      rainy      snowy      total\n",
      "timeofday                                                   \n",
      "daytime      0.0   5.123810  79.485714  76.895238  40.376190\n",
      "night        0.0  99.161905  79.485714  76.895238  63.885714\n",
      "total        0.0  52.142857  79.485714  76.895238  52.130952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/till/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:90: InsufficientSamplesWarning: Number of available sample images is smaller than number of requested images.\n"
     ]
    }
   ],
   "source": [
    "cfg = bdd.GetConfig(cfg_name)\n",
    "# third, we get all the different train sets; note we are not updating the remaining available samples here\n",
    "sampler_table[\"train_A\"], over_table[\"train_A\"] = stratified_sampler(crosstab_total, crosstab_avail, cfg.sampler_dict[\"train_A\"])\n",
    "sampler_table[\"train_B\"], over_table[\"train_B\"] = stratified_sampler(crosstab_total, crosstab_avail, cfg.sampler_dict[\"train_B\"])\n",
    "sampler_table[\"train_C\"], over_table[\"train_C\"] = stratified_sampler(crosstab_total, crosstab_avail, cfg.sampler_dict[\"train_C\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = [k for k in cfg.sampler_dict.keys() if 'train' in k]\n",
    "sets = [\"set_\"+k[-1] for k in train_sets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the train-dev sets are taken as subsets of the train sets\n",
    "for train_set in train_sets:\n",
    "    train_dev_set = \"train_dev_\" + train_set[-1]\n",
    "    sampler_table[train_dev_set] = sampler_table[train_set] * cfg.train_dev_n / cfg.sampler_dict[train_set][\"n\"]\n",
    "    sampler_table[train_set] = sampler_table[train_set] - sampler_table[train_dev_set]\n",
    "    over_table[train_dev_set] = over_table[train_set] * cfg.train_dev_n / cfg.sampler_dict[train_set][\"n\"]\n",
    "    over_table[train_set] = over_table[train_set] - over_table[train_dev_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to the dataframe indicating split association (train, train-dev, dev, and test set)\n",
    "data[\"set_all\"] = 'unassigned'\n",
    "for s in sets:\n",
    "    data[s] = 'unassigned'  # initialize with all 'unassigned'\n",
    "    data[s+\"_n_over\"] = 0\n",
    "# shuffle data and reset index\n",
    "data = data.sample(frac=1.0, random_state=123).reset_index(drop=True)\n",
    "# set seed for numpy\n",
    "np.random.seed(123)\n",
    "\n",
    "# stratified random sampling of indices for split sets based on sampler_table\n",
    "for split, table in sampler_table.items():  # for each split\n",
    "    for tod in table.index:  # for each timeofday\n",
    "        for wc in table.columns:  # for each weather condition\n",
    "            n_samples = int(table.loc[tod,wc])\n",
    "            if n_samples > 0:\n",
    "                if split in [\"valid\", \"test\"]:\n",
    "                    class_idx = data[(data.set_all.eq('unassigned') & data.timeofday.eq(tod) & data.weather.eq(wc))].index\n",
    "                    idx = class_idx[0:n_samples]  # np.random.choice(self.data.index[class_bool].values, size=n_samples, replace=False)\n",
    "                    data.loc[idx,[\"set_all\", *sets]] = split\n",
    "                else:\n",
    "                    cur_set = \"set_\"+split[-1]\n",
    "                    if \"train\" in split and \"train_dev\" not in split:\n",
    "                        # try to use data already in another train set\n",
    "                        idx = data[(data.set_all.str.contains('train') & data.timeofday.eq(tod) & data.weather.eq(wc))].index\n",
    "                        n = idx.size\n",
    "                        if n >= n_samples:\n",
    "                            idx = idx[0:n_samples]\n",
    "                        else:\n",
    "                            idx_add = data[(data.set_all.eq('unassigned') & data.timeofday.eq(tod) & data.weather.eq(wc))].index\n",
    "                            idx = np.hstack([idx, idx_add[0:n_samples - n]] )\n",
    "                        data.loc[idx,[\"set_all\", cur_set]] = \"train\"\n",
    "                    elif \"train_dev\" in split:\n",
    "                        # try to use data already in another train dev set\n",
    "                        idx = data[(data.set_all.str.contains('train_dev') & data.timeofday.eq(tod) & data.weather.eq(wc))].index\n",
    "                        n = idx.size\n",
    "                        if n >= n_samples:\n",
    "                            idx = idx[0:n_samples]\n",
    "                        else:\n",
    "                            # try to use data already in another train set\n",
    "                            idx_add = data[(data.set_all.str.contains('train') & ~data[cur_set].str.contains('train') & data.timeofday.eq(tod) & data.weather.eq(wc))].index\n",
    "                            n_add = idx_add.size\n",
    "                            idx = np.hstack([idx, idx_add[0:np.minimum(n_samples - n, n_add)]] ) \n",
    "                            n = idx.size\n",
    "                            if n < n_samples:\n",
    "                                idx_add = data[(data.set_all.eq('unassigned') & data.timeofday.eq(tod) & data.weather.eq(wc))].index\n",
    "                                n_add = idx_add.size\n",
    "                                idx = np.hstack([idx, idx_add[0:np.minimum(n_samples - n, n_add)]] ) \n",
    "                        data.loc[idx,[\"set_all\", cur_set]] = \"train_dev\"\n",
    "                    # store number of over-samples\n",
    "                    idx_over = np.random.choice(idx, over_table[split].loc[tod,wc].astype(\"int\"))\n",
    "                    idx_uni, counts = np.unique(idx_over, return_counts=True)\n",
    "                    data.loc[idx_uni, cur_set+\"_n_over\"] = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a useful info_dict containing info about each split element of sampler dict\n",
    "info_dict = {}\n",
    "info_dict[\"splits\"] = sampler_table.keys()\n",
    "for split in info_dict[\"splits\"]:\n",
    "    info_dict[split] = {}\n",
    "    # set association\n",
    "    if split in [\"test\", \"valid\"]:\n",
    "        info_dict[split][\"set\"] = \"set_all\"\n",
    "    else:\n",
    "        info_dict[split][\"set\"] = \"set_\" + split[-1]\n",
    "    # part name\n",
    "    if split in [\"test\", \"valid\"]:\n",
    "        info_dict[split][\"split\"] = split\n",
    "    else:\n",
    "        info_dict[split][\"split\"] = split[:-2]\n",
    "    # destination path\n",
    "    if cfg.do_make_dirs:  # create a separate dir for each split\n",
    "        info_dict[split][\"destination_path\"] = os.path.join(cfg.destination_path, split)\n",
    "    else:  # create all files in the same dir\n",
    "        info_dict[split][\"destination_path\"] = cfg.destination_path\n",
    "    # destination file names\n",
    "    info_dict[split][\"destination_json_filename\"] = cfg.destination_filename_stem + split + \".json\"        \n",
    "    info_dict[split][\"destination_json_over_filename\"] = cfg.destination_filename_stem + split + \"_over\" + \".json\"        \n",
    "    # destination file path\n",
    "    info_dict[split][\"destination_json_filepath\"] = os.path.join(info_dict[split][\"destination_path\"], info_dict[split][\"destination_json_filename\"])\n",
    "    info_dict[split][\"destination_json_over_filepath\"] = os.path.join(info_dict[split][\"destination_path\"], info_dict[split][\"destination_json_over_filename\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_to_bddjson(df, dest_path):\n",
    "    ### Prepare data frame for json output\n",
    "    # revolve formatting back to BDD original formatting\n",
    "    df[\"timestamp\"] = 1000\n",
    "    df.name = df.name.apply(os.path.basename)\n",
    "    df[\"attributes\"] = df.apply(lambda row: {'weather':row['weather'], 'scene':row['scene'], 'timeofday':row['timeofday']}, axis=1)  # This gives warning: another try: cur_file[\"attributes\"] = [{'weather': we, 'scene': sc, 'timeofday': tod} for we, sc, tod in zip(cur_file.weather, cur_file.scene, cur_file.timeofday)]\n",
    "    df = df[[\"attributes\", \"labels\", \"name\", \"timestamp\"]]\n",
    "    # write json file to hdd\n",
    "    df.to_json(path_or_buf=dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 2000 images to /home/till/data/driving/BerkeleyDeepDrive/bdd100k_sorted/test\n",
      "Copying 2000 images to /home/till/data/driving/BerkeleyDeepDrive/bdd100k_sorted/valid\n",
      "Copying 23848 images to /home/till/data/driving/BerkeleyDeepDrive/bdd100k_sorted/train_A\n",
      "Over-sampling done for 4000 of 23848 entries.\n",
      "Over-sampling done for 4000 of 23848 entries.\n",
      "Over-sampling done for 4000 of 23848 entries.\n",
      "Over-sampling done for 4000 of 23848 entries.\n",
      "Over-sampling done for 4000 of 23848 entries.\n",
      "Over-sampling done for 4000 of 23848 entries.\n",
      "Over-sampling done for 4000 of 23848 entries.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8f9030cd9276>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mn_over\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_over\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mcur_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0;31m# make physical copies of the oversamples, if requested\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_oversample_physically\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m                         \u001b[0msetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36msetter\u001b[0;34m(item, v)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m                 \u001b[0;31m# reset the sliced object if unique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mcan_do_equal_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3368\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3369\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3370\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cfg = bdd.GetConfig(cfg_name)\n",
    "# now separate data, copy images, and create the different jsons\n",
    "for split in info_dict[\"splits\"]:  # for each split\n",
    "    \n",
    "    ### get all elements associated with the current split into a separate data frame\n",
    "    if split in [\"test\", \"valid\"]:\n",
    "        cur_file = data.query(\"set_all==@split\").reset_index(drop=True)\n",
    "    else:\n",
    "        # cur_split = info_dict[split]['split']\n",
    "        cur_split = info_dict[split]['split']\n",
    "        cur_file = data.query(\"{}==@cur_split\".format(info_dict[split]['set'])).reset_index(drop=True)\n",
    "    \n",
    "    ### create folder structure\n",
    "    if not os.path.exists(info_dict[split][\"destination_path\"]):\n",
    "        os.makedirs(info_dict[split][\"destination_path\"])\n",
    "    else:\n",
    "        raise Exception  # ...\n",
    "        \n",
    "    ### save a json in bdd format containing only the original images\n",
    "    pandas_to_bddjson(cur_file.copy(), info_dict[split][\"destination_json_filepath\"])\n",
    "\n",
    "    ### copy original images associated with current split into new folder\n",
    "    if cfg.do_copy_images:\n",
    "        print(\"Copying {} images to {}\".format(cur_file.shape[0], info_dict[split][\"destination_path\"]))\n",
    "        for img_path in cur_file[\"name\"]:\n",
    "            copyfile(img_path, os.path.join(info_dict[split][\"destination_path\"], os.path.basename(img_path)))\n",
    "        \n",
    "    ### append oversamples to cur_file (file names = original file name + copy1, copy2, etc.\n",
    "    if split not in [\"test\", \"valid\"]:\n",
    "        col_name = info_dict[split]['set']+\"_n_over\"\n",
    "        cf_shape_before = cur_file.shape[0]\n",
    "        for i in range(cf_shape_before):\n",
    "            n_over = int(cur_file.loc[i,col_name])\n",
    "            for j in range(n_over):\n",
    "                cur_file.loc[cur_file.shape[0],:] = cur_file.loc[i,:]\n",
    "                # make physical copies of the oversamples, if requested\n",
    "                if cfg.do_oversample_physically:\n",
    "                    asdasd=adadassd\n",
    "                    name_original = cur_file.loc[i, \"name\"]\n",
    "                    name_copy = os.path.join(info_dict[split][\"destination_path\"], os.path.basename(name_original.split(\".\")[0] + \"_copy\" + str(j+1) + \".\" + name_original.split(\".\")[1]))  # rename file by appending _copy1, _copy2, etc\n",
    "                    print(name_original, '>>>\\n', name_copy)\n",
    "                    copyfile(name_original, name_copy)\n",
    "                    cur_file.loc[cur_file.shape[0]-1, \"name\"] = name_copy  # store the new name\n",
    "            if i%1000==0:\n",
    "                print(\"Over-sampling done for {} of {} entries.\".format(i, cf_shape_before))\n",
    "                \n",
    "    ### save a json in bdd format containing also the over-samples\n",
    "    pandas_to_bddjson(cur_file.copy(), info_dict[split][\"destination_json_over_filepath\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the main data set to a json file\n",
    "data.to_json(os.path.join(cfg.destination_path, cfg.destination_filename_stem + \"main\" + \".json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fname = \"/home/till/data/driving/BerkeleyDeepDrive/bdd100k_sorted/test/bdd100k_sorted_test.json\"\n",
    "df = pd.read_json(test_fname)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fname = \"/home/till/data/driving/BerkeleyDeepDrive/bdd100k/labels/bdd100k_labels_images_val.json\"\n",
    "df2 = pd.read_json(test_fname)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_template = \n",
    "{\n",
    "\"info\": info,\n",
    "\"images\": [image],\n",
    "\"annotations\": [annotation],\n",
    "\"licenses\": [license],\n",
    "}\n",
    "info{\"year\": -999,\n",
    "    \"version\": -999,\n",
    "    \"description\": \"empty\",\n",
    "    \"contributor\": \"empty\",\n",
    "    \"url\": \"empty\",\n",
    "    \"date_created\": 2012-04-23T18:25:43.511Z,\n",
    "}\n",
    "\n",
    "image{\n",
    "    \"id\": int,\n",
    "    \"width\": int,\n",
    "    \"height\": int,\n",
    "    \"file_name\": str,\n",
    "    \"license\": int,\n",
    "    \"flickr_url\": str,\n",
    "    \"coco_url\": str,\n",
    "    \"date_captured\": 2012-04-23T18:25:43.511Z,\n",
    "}\n",
    "\n",
    "license{\n",
    "    \"id\": -999,\n",
    "    \"name\": \"empty\",\n",
    "    \"url\": \"empty\",\n",
    "}\n",
    "\n",
    "annotation{\n",
    "\"id\": int,\n",
    "\"image_id\": int,\n",
    "\"category_id\": int,\n",
    "\"segmentation\": RLE or [polygon],\n",
    "\"area\": float,\n",
    "\"bbox\": [x,y,width,height],\n",
    "\"iscrowd\": 0 or 1,\n",
    "}\n",
    "\n",
    "categories[{\n",
    "\"id\": int,\n",
    "\"name\": str,\n",
    "\"supercategory\": str,\n",
    "}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOT USED #######\n",
    "\n",
    "# third, we get all the different train sets; note we are not updating the remaining available samples here\n",
    "# get some helepers\n",
    "train_sets = [k for k in cfg.sampler_dict.keys() if 'train' in k]\n",
    "max_night = 0\n",
    "max_day = 0\n",
    "for train_set in train_sets:\n",
    "    if cfg.sampler_dict[train_set][\"class_dist\"][\"daytime\"] > max_day:\n",
    "        train_set_max_day = train_set; max_day = cfg.sampler_dict[train_set][\"class_dist\"][\"daytime\"]\n",
    "    if cfg.sampler_dict[train_set][\"class_dist\"][\"night\"] > max_night:\n",
    "        train_set_max_night = train_set; max_night = cfg.sampler_dict[train_set][\"class_dist\"][\"night\"]\n",
    "train_sets_intermediate = [s for s in train_sets if s not in [train_set_max_night,train_set_max_day]]\n",
    "\n",
    "# get sampler tables for \n",
    "sampler_table[train_set_max_day], over_table[train_set_max_day] = stratified_sampler(crosstab_total, crosstab_avail, cfg.sampler_dict[train_set_max_day])\n",
    "sampler_table[train_set_max_night], over_table[train_set_max_night] = stratified_sampler(crosstab_total, crosstab_avail, cfg.sampler_dict[train_set_max_night])\n",
    "#\n",
    "for train_set in train_sets_intermediate:\n",
    "    sampler_table[train_set], over_table[train_set] = sampler_table[train_set_max_day].copy(), over_table[train_set_max_day].copy()\n",
    "    sampler_table[train_set].\n",
    "# note, if not "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
